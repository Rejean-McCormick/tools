{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### [\ud83c\udfe0 **Home**](NoteBookIndex.ipynb) &nbsp; | &nbsp; [\u23ea **Prev** (01-stability-and-resilience)](senior-architecture-patterns_20251215_1232_01_01-stability-and-resilience.ipynb) &nbsp; | &nbsp; [**Next** (02-structural-and-decoupling) \u23e9](senior-architecture-patterns_20251215_1232_03_02-structural-and-decoupling.ipynb)\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# FOLDER: 03-data-management-consistency\n",
        "**Generated:** 2025-12-15 12:32\n",
        "\n",
        "**Contains:** 6 files | **Total Size:** 0.03 MB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udcc2 `03-data-management-consistency/`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### \ud83d\udcc4 `03-data-management-consistency/12-cqrs.md`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 12\\. CQRS (Command Query Responsibility Segregation)\n",
        "\n",
        "## 1\\. The Concept\n",
        "\n",
        "CQRS is an architectural pattern that separates the data mutation operations (Commands) from the data retrieval operations (Queries). Instead of using a single model (like a User class or a single SQL table) for both reading and writing, you create two distinct models: one optimized for updating information and another optimized for reading it.\n",
        "\n",
        "## 2\\. The Problem\n",
        "\n",
        "  * **Scenario:** You have a high-traffic \"Social Media Feed\" application.\n",
        "      * **Writes:** Users post updates, which require complex validation, transaction integrity, and normalization (3rd Normal Form) to prevent data corruption.\n",
        "      * **Reads:** Millions of users scroll through feeds. This requires massive joins across 10 tables (Users, Posts, Likes, Comments, Media) to show a single screen.\n",
        "  * **The Bottleneck:**\n",
        "      * **The Tug-of-War:** Optimizing the database for writes (normalization) kills read performance (too many joins). Optimizing for reads (denormalization) makes writes slow and dangerous.\n",
        "      * **Locking:** A user updating their profile locks the row, potentially blocking someone else from reading it.\n",
        "\n",
        "## 3\\. The Solution\n",
        "\n",
        "Split the system into two sides:\n",
        "\n",
        "1.  **The Command Side (Write Model):** Handles `Create`, `Update`, `Delete`. It uses a normalized database (e.g., PostgreSQL) focused on data integrity and ACID transactions. It doesn't care about query speed.\n",
        "2.  **The Query Side (Read Model):** Handles `Get`, `List`, `Search`. It uses a denormalized database (e.g., ElasticSearch, Redis, or a flat SQL table) pre-calculated for the UI. It doesn't perform business logic; it just reads fast.\n",
        "\n",
        "The two sides are kept in sync, usually asynchronously (Eventual Consistency).\n",
        "\n",
        "### Junior vs. Senior View\n",
        "\n",
        "| Perspective | Approach | Outcome |\n",
        "| :--- | :--- | :--- |\n",
        "| **Junior** | \"We have a `User` table. We use it for login, profile updates, and searching. If search is slow, add more indexes.\" | **The Monolith Trap.** Adding indexes speeds up reads but slows down writes. Eventually, the database creates a deadlock under load. |\n",
        "| **Senior** | \"The `User` table is for writing. For the 'User Search' feature, we project the data into an ElasticSearch index. The search API never touches the primary SQL DB.\" | **Performance at Scale.** Writes remain safe and transactional. Reads are instant. The load is physically separated. |\n",
        "\n",
        "## 4\\. Visual Diagram\n",
        "\n",
        "## 5\\. When to Use It (and When NOT to)\n",
        "\n",
        "  * \u2705 **Use when:**\n",
        "      * **Asymmetric Traffic:** You have 1,000 reads for every 1 write (very common in web apps).\n",
        "      * **Complex Views:** The UI needs data in a shape that looks nothing like the database schema (e.g., a dashboard aggregating 5 different business entities).\n",
        "      * **High Performance:** You need sub-millisecond read times that standard SQL joins cannot provide.\n",
        "  * \u274c **Avoid when:**\n",
        "      * **Simple CRUD:** If your app is just \"Edit User\" and \"View User,\" CQRS adds massive complexity (syncing data, handling lag) for no benefit.\n",
        "      * **Strict Consistency:** If the user *must* see their update instantly (e.g., updating a bank balance), the lag introduced by CQRS sync can be dangerous.\n",
        "\n",
        "## 6\\. Implementation Example (Pseudo-code)\n",
        "\n",
        "**Scenario:** A user updates their address.\n",
        "\n",
        "### 1\\. The Command Side (Write)\n",
        "\n",
        "*Focused on rules and integrity.*\n",
        "\n",
        "```python\n",
        "# Command Handler\n",
        "def handle_update_address(user_id, new_address):\n",
        "    # 1. Validation (Business Logic)\n",
        "    if not is_valid(new_address):\n",
        "        raise ValidationError(\"Invalid Address\")\n",
        "\n",
        "    # 2. Update Primary DB (3rd Normal Form)\n",
        "    # Allows for fast, safe updates with no redundancy\n",
        "    sql_db.execute(\n",
        "        \"UPDATE users SET street=?, city=? WHERE id=?\", \n",
        "        (new_address.street, new_address.city, user_id)\n",
        "    )\n",
        "\n",
        "    # 3. Publish Event (The Sync Mechanism)\n",
        "    event_bus.publish(\"UserAddressUpdated\", {\n",
        "        \"user_id\": user_id,\n",
        "        \"full_address\": f\"{new_address.street}, {new_address.city}\" \n",
        "    })\n",
        "```\n",
        "\n",
        "### 2\\. The Query Side (Read)\n",
        "\n",
        "*Focused on speed. No logic.*\n",
        "\n",
        "```python\n",
        "# Event Listener (Background Worker)\n",
        "def on_user_address_updated(event):\n",
        "    # Update the Read DB (Denormalized / NoSQL)\n",
        "    # This document is pre-formatted exactly how the UI needs it\n",
        "    mongo_db.users_view.update_one(\n",
        "        {\"_id\": event.user_id},\n",
        "        {\"$set\": {\"display_address\": event.full_address}}\n",
        "    )\n",
        "\n",
        "# Query Handler (API)\n",
        "def get_user_profile(user_id):\n",
        "    # 0 joins. O(1) complexity. Instant.\n",
        "    return mongo_db.users_view.find_one({\"_id\": user_id})\n",
        "```\n",
        "\n",
        "## 7\\. The Cost: Eventual Consistency\n",
        "\n",
        "The biggest trade-off with CQRS is **Consistency lag**.\n",
        "\n",
        "  * The user clicks \"Save.\"\n",
        "  * The Command Service says \"Success.\"\n",
        "  * The user is redirected to the \"View Profile\" page.\n",
        "  * **The Problem:** The Event hasn't processed yet. The \"View\" page still shows the *old* address. The user thinks the system is broken.\n",
        "\n",
        "**Senior Solutions:**\n",
        "\n",
        "1.  **Optimistic UI:** The frontend updates the UI immediately using JavaScript, assuming the server will catch up.\n",
        "2.  **Read-Your-Own-Writes:** The \"View\" API checks the replication lag or reads from the Write DB for a few seconds after an update.\n",
        "3.  **Acceptance:** In many cases (e.g., Facebook Likes), it doesn't matter if the count is wrong for 2 seconds.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### \ud83d\udcc4 `03-data-management-consistency/13-event-sourcing.md`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 13\\. Event Sourcing\n",
        "\n",
        "## 1\\. The Concept\n",
        "\n",
        "Event Sourcing is an architectural pattern where the state of an application is determined by a sequence of events, rather than just the current state. Instead of overwriting data in a database (CRUD), you store every change that has ever happened as an immutable \"Event\" in an append-only log. The current state is derived by replaying these events from the beginning.\n",
        "\n",
        "## 2\\. The Problem\n",
        "\n",
        "  * **Scenario:** A Banking System.\n",
        "      * **Day 1:** User A opens an account with $0.\n",
        "      * **Day 2:** User A deposits $100.\n",
        "      * **Day 3:** User A withdraws $50.\n",
        "  * **The CRUD Reality:** In a standard SQL database, the `Accounts` table just says `Balance: $50`.\n",
        "  * **The Risk:**\n",
        "      * **Loss of History:** We have lost the information about *how* we got to $50. Did they deposit $50? Or did they deposit $1000 and withdraw $950?\n",
        "      * **Auditability:** If the user claims \"I never withdrew that money,\" you have no proof in the primary database state. You have to dig through messy text logs (if they exist).\n",
        "      * **Debugging:** If a bug corrupted the balance to -$10, you can't replay the sequence to find out exactly which transaction caused the math error.\n",
        "\n",
        "## 3\\. The Solution\n",
        "\n",
        "Store the **Events**, not the **State**.\n",
        "Instead of a table with a \"Balance\" column, you have an \"Events\" table:\n",
        "\n",
        "1.  `AccountOpened { Id: 1, Balance: 0 }`\n",
        "2.  `MoneyDeposited { Id: 1, Amount: 100 }`\n",
        "3.  `MoneyWithdrawn { Id: 1, Amount: 50 }`\n",
        "\n",
        "To find the balance, the system loads all events for ID 1 and does the math: `0 + 100 - 50 = 50`.\n",
        "\n",
        "### Junior vs. Senior View\n",
        "\n",
        "| Perspective | Approach | Outcome |\n",
        "| :--- | :--- | :--- |\n",
        "| **Junior** | \"We just need the current address. `UPDATE users SET address = 'New York' WHERE id=1`.\" | **Data Amnesia.** The old address is gone forever. We cannot answer questions like \"Where did this user live last year?\" |\n",
        "| **Senior** | \"Don't overwrite. Append an `AddressChanged` event. We can project the 'Current State' for the UI, but the source of truth is the history.\" | **Time Travel.** We can query the state of the system at *any point in time*. We have a perfect audit trail by default. |\n",
        "\n",
        "## 4\\. Visual Diagram\n",
        "\n",
        "## 5\\. When to Use It (and When NOT to)\n",
        "\n",
        "  * \u2705 **Use when:**\n",
        "      * **Audit is Critical:** Banking, Healthcare, Law, Insurance.\n",
        "      * **Debugging is Hard:** Complex logic where \"how we got here\" matters as much as \"where we are.\"\n",
        "      * **Temporal Queries:** You need to answer \"What was the inventory level on December 24th?\"\n",
        "      * **Intent Capture:** \"CartAbandoned\" is a valuable business event that is lost if you just delete the cart row in SQL.\n",
        "  * \u274c **Avoid when:**\n",
        "      * **Simple CRUD:** A blog post or a to-do list. Overkill.\n",
        "      * **High Churn, Low Value:** Storing every mouse movement or temporary session data (unless for analytics).\n",
        "      * **GDPR Nightmares:** If you write personal data into an immutable log, you need a strategy (like Crypto-Shredding) to \"forget\" it later.\n",
        "\n",
        "## 6\\. Implementation Example (Pseudo-code)\n",
        "\n",
        "**Scenario:** A Bank Account.\n",
        "\n",
        "```python\n",
        "# 1. THE EVENTS (Immutable Data Classes)\n",
        "class AccountCreated:\n",
        "    def __init__(self, account_id, owner):\n",
        "        self.type = \"AccountCreated\"\n",
        "        self.account_id = account_id\n",
        "        self.owner = owner\n",
        "\n",
        "class MoneyDeposited:\n",
        "    def __init__(self, amount):\n",
        "        self.type = \"MoneyDeposited\"\n",
        "        self.amount = amount\n",
        "\n",
        "class MoneyWithdrawn:\n",
        "    def __init__(self, amount):\n",
        "        self.type = \"MoneyWithdrawn\"\n",
        "        self.amount = amount\n",
        "\n",
        "# 2. THE AGGREGATE (The Logic)\n",
        "class BankAccount:\n",
        "    def __init__(self):\n",
        "        self.balance = 0\n",
        "        self.id = None\n",
        "        self.changes = [] # New events to be saved\n",
        "\n",
        "    # The Decision: Validate and create event\n",
        "    def withdraw(self, amount):\n",
        "        if self.balance < amount:\n",
        "            raise Exception(\"Insufficient Funds\")\n",
        "        \n",
        "        event = MoneyWithdrawn(amount)\n",
        "        self.changes.append(event)\n",
        "        self.apply(event)\n",
        "\n",
        "    # The State Change: Apply event to current state\n",
        "    def apply(self, event):\n",
        "        if event.type == \"AccountCreated\":\n",
        "            self.id = event.account_id\n",
        "        elif event.type == \"MoneyDeposited\":\n",
        "            self.balance += event.amount\n",
        "        elif event.type == \"MoneyWithdrawn\":\n",
        "            self.balance -= event.amount\n",
        "\n",
        "    # The Hydration: Rebuild from history\n",
        "    def load_from_history(self, events):\n",
        "        for event in events:\n",
        "            self.apply(event)\n",
        "\n",
        "# 3. USAGE\n",
        "# Load from DB\n",
        "history = event_store.get_events(account_id=\"ACC_123\")\n",
        "account = BankAccount()\n",
        "account.load_from_history(history) # Balance is now calculated\n",
        "\n",
        "# Do logic\n",
        "account.withdraw(50)\n",
        "\n",
        "# Save new events\n",
        "event_store.save(account.changes)\n",
        "```\n",
        "\n",
        "## 7\\. Performance: The Snapshot Pattern\n",
        "\n",
        "**Problem:** If an account is 10 years old and has 50,000 transactions, replaying 50k events every time the user logs in is too slow.\n",
        "\n",
        "**Solution:** **Snapshots.**\n",
        "Every 100 events (or every night), calculate the state and save it to a separate \"Snapshot Store.\"\n",
        "\n",
        "  * *Snapshot (Event \\#49,900):* `Balance = $4050`.\n",
        "  * To load the account, load the latest Snapshot + any events that happened *after* it.\n",
        "  * You now only replay 5 events instead of 50,000.\n",
        "\n",
        "## 8\\. Deleting Data (The \"Right to be Forgotten\")\n",
        "\n",
        "Since the Event Log is immutable (Write Once, Read Many), you cannot `DELETE` a user's address to comply with GDPR.\n",
        "\n",
        "**Strategy: Crypto-Shredding.**\n",
        "\n",
        "1.  Encrypt all PII (Personally Identifiable Information) in the event payload using a specific key for that user ID.\n",
        "2.  Store the Key in a separate \"Key Vault\" (standard SQL DB).\n",
        "3.  To \"Delete\" the user: **Delete the Key.**\n",
        "4.  The events remain in the log, but the data is essentially garbage/unreadable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### \ud83d\udcc4 `03-data-management-consistency/14-saga-pattern.md`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 14\\. Saga Pattern\n",
        "\n",
        "## 1\\. The Concept\n",
        "\n",
        "The Saga Pattern is a mechanism for managing long-running transactions in a distributed system. Instead of relying on a global \"lock\" across multiple databases (which is slow and fragile), a Saga breaks the transaction into a sequence of smaller, local transactions. If any step fails, the Saga executes a series of \"Compensating Transactions\" to undo the changes made by the previous steps.\n",
        "\n",
        "## 2\\. The Problem\n",
        "\n",
        "  * **Scenario:** A Travel Booking System. To book a trip, you must:\n",
        "    1.  Book a Flight (Flight Service).\n",
        "    2.  Reserve a Hotel (Hotel Service).\n",
        "    3.  Charge the Credit Card (Payment Service).\n",
        "  * **The Constraint:** These are three different microservices with three different databases. You cannot use a standard SQL Transaction (`BEGIN TRANSACTION ... COMMIT`).\n",
        "  * **The Risk:**\n",
        "      * You successfully book the flight.\n",
        "      * You successfully reserve the hotel.\n",
        "      * **The Payment Fails** (insufficient funds).\n",
        "      * **Result:** The system is in an inconsistent state. The user has a flight and hotel but hasn't paid. The airline and hotel hold onto seats/rooms that will never be used (Zombie Reservations).\n",
        "\n",
        "## 3\\. The Solution\n",
        "\n",
        "We define a workflow where every \"Do\" action has a corresponding \"Undo\" action.\n",
        "\n",
        "| Step | Action (Transaction) | Compensation (Undo) |\n",
        "| :--- | :--- | :--- |\n",
        "| **1** | `BookFlight()` | `CancelFlight()` |\n",
        "| **2** | `ReserveHotel()` | `CancelHotel()` |\n",
        "| **3** | `ChargeCard()` | `RefundCard()` |\n",
        "\n",
        "If Step 3 (`ChargeCard`) fails, the Saga Orchestrator catches the error and runs the compensations in reverse order:\n",
        "\n",
        "1.  Execute `CancelHotel()`.\n",
        "2.  Execute `CancelFlight()`.\n",
        "3.  Report \"Booking Failed\" to the user.\n",
        "\n",
        "The system eventually returns to a consistent state (nothing booked, nothing charged).\n",
        "\n",
        "### Junior vs. Senior View\n",
        "\n",
        "| Perspective | Approach | Outcome |\n",
        "| :--- | :--- | :--- |\n",
        "| **Junior** | \"Use Two-Phase Commit (2PC / XA Transactions) across all databases to ensure everything commits at the exact same time.\" | **Gridlock.** 2PC holds locks on all databases until the slowest one finishes. Performance plummets. If the coordinator crashes, the databases stay locked. |\n",
        "| **Senior** | \"Accept that we can't lock the world. Use Sagas. If the payment fails, we issue a refund. It's how real-world business works.\" | **Scalability.** Services are loosely coupled. No global locks. The system handles partial failures gracefully. |\n",
        "\n",
        "## 4\\. Visual Diagram\n",
        "\n",
        "## 5\\. Types of Sagas\n",
        "\n",
        "There are two main ways to coordinate a Saga:\n",
        "\n",
        "### A. Choreography (Event-Driven)\n",
        "\n",
        "  * **Concept:** Services talk to each other directly via events. No central manager.\n",
        "  * **Flow:** Flight Service does its job -\\> Emits `FlightBooked` -\\> Hotel Service listens, does its job -\\> Emits `HotelBooked`.\n",
        "  * **Pros:** Simple, decentralized, no single point of failure.\n",
        "  * **Cons:** Hard to debug. \"Who triggered this refund?\" can be a mystery. Circular dependencies are possible.\n",
        "\n",
        "### B. Orchestration (Command-Driven)\n",
        "\n",
        "  * **Concept:** A central \"Orchestrator\" (State Machine) tells each service what to do.\n",
        "  * **Flow:** Orchestrator calls `FlightService.book()`. If success, Orchestrator calls `HotelService.reserve()`.\n",
        "  * **Pros:** Clear logic, centralized monitoring, easy to handle timeouts.\n",
        "  * **Cons:** The Orchestrator can become a bottleneck or a \"God Service\" with too much logic.\n",
        "\n",
        "## 6\\. When to Use It (and When NOT to)\n",
        "\n",
        "  * \u2705 **Use when:**\n",
        "      * **Distributed Data:** Transactions span multiple microservices.\n",
        "      * **Long-Running Flows:** The process takes minutes or hours (e.g., \"Order Fulfillment\").\n",
        "      * **Reversible Actions:** You can logically \"Undo\" an action (Refund, Cancel, Restock).\n",
        "  * \u274c **Avoid when:**\n",
        "      * **Irreversible Actions:** If Step 1 is \"Send Email\" or \"Fire Missile,\" you can't undo it. (You might need a pseudo-compensation like sending a \"Sorry\" email).\n",
        "      * **Read Isolation:** Sagas do not support ACID \"Isolation.\" A user might see the Flight booked *before* the Payment fails. This is called a \"Dirty Read.\"\n",
        "\n",
        "## 7\\. Implementation Example (Pseudo-code)\n",
        "\n",
        "**Scenario:** Orchestration-based Saga for the Travel App.\n",
        "\n",
        "```python\n",
        "class TravelSaga:\n",
        "    def __init__(self, flight_svc, hotel_svc, pay_svc):\n",
        "        self.flight_svc = flight_svc\n",
        "        self.hotel_svc = hotel_svc\n",
        "        self.pay_svc = pay_svc\n",
        "\n",
        "    def execute_booking(self, user_id, trip_details):\n",
        "        # 1. Step 1: Flight\n",
        "        try:\n",
        "            flight_id = self.flight_svc.book_flight(trip_details)\n",
        "        except Exception:\n",
        "            # Failed at start. No compensation needed.\n",
        "            return \"Failed\"\n",
        "\n",
        "        # 2. Step 2: Hotel\n",
        "        try:\n",
        "            hotel_id = self.hotel_svc.reserve_hotel(trip_details)\n",
        "        except Exception:\n",
        "            # Hotel failed. UNDO Flight.\n",
        "            self.flight_svc.cancel_flight(flight_id)\n",
        "            return \"Failed\"\n",
        "\n",
        "        # 3. Step 3: Payment\n",
        "        try:\n",
        "            self.pay_svc.charge_card(user_id)\n",
        "        except Exception:\n",
        "            # Payment failed. UNDO Hotel AND Flight.\n",
        "            self.hotel_svc.cancel_hotel(hotel_id)\n",
        "            self.flight_svc.cancel_flight(flight_id)\n",
        "            return \"Failed\"\n",
        "\n",
        "        return \"Success\"\n",
        "```\n",
        "\n",
        "## 8\\. Strategic Note: The \"Pending\" State\n",
        "\n",
        "Because Sagas lack Isolation (the \"I\" in ACID), other users might see intermediate states.\n",
        "\n",
        "  * **Senior Tip:** Don't show the flight as \"Booked\" immediately.\n",
        "  * Show it as **\"Pending Approval\"**.\n",
        "  * Only flip the status to \"Confirmed\" once the Saga completes successfully.\n",
        "  * If the Saga fails, flip it to \"Rejected.\"\n",
        "  * This manages user expectations and prevents \"Dirty Reads\" from confusing the customer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### \ud83d\udcc4 `03-data-management-consistency/15-idempotency.md`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 15\\. Idempotency\n",
        "\n",
        "## 1\\. The Concept\n",
        "\n",
        "Idempotency is a property of an operation whereby it can be applied multiple times without changing the result beyond the initial application. In distributed systems, this means that if a client sends the same request twice (due to a retry, a network glitch, or a double-click), the server processes it only once and returns the same response.\n",
        "\n",
        "Mathematically, $f(f(x)) = f(x)$.\n",
        "\n",
        "## 2\\. The Problem\n",
        "\n",
        "  * **Scenario:** A user is purchasing a concert ticket. They click \"Pay $100.\"\n",
        "      * **The Glitch:** The user's WiFi flickers. The browser doesn't receive the \"Success\" confirmation, so the frontend code (or the impatient user) retries the request.\n",
        "      * **The Backend Reality:** The first request *did* reach the server and charged the credit card. The second request *also* reaches the server.\n",
        "  * **The Risk (Double Charge):** Without idempotency, the server sees two valid requests and charges the user $200. This destroys trust and creates a customer support nightmare.\n",
        "\n",
        "## 3\\. The Solution\n",
        "\n",
        "Assign a unique **Idempotency Key** (or Request ID) to every transactional request.\n",
        "\n",
        "1.  **Client:** Generates a unique UUID (e.g., `req_123`) for the \"Pay\" action.\n",
        "2.  **Server:** Checks its cache/database: \"Have I seen `req_123` before?\"\n",
        "      * **No:** Process the payment. Save `req_123` + Response in the database. Return Success.\n",
        "      * **Yes:** Stop\\! Do not process again. Retrieve the saved Response from the database and return it immediately.\n",
        "\n",
        "### Junior vs. Senior View\n",
        "\n",
        "| Perspective | Approach | Outcome |\n",
        "| :--- | :--- | :--- |\n",
        "| **Junior** | \"I'll just check if the user has bought a ticket in the last 5 minutes.\" | **Race Conditions.** If two requests arrive at the exact same millisecond, both might pass the check before the database records the first one. |\n",
        "| **Senior** | \"Require an `Idempotency-Key` header. Use a unique constraint in the database or an atomic `SET NX` in Redis to ensure strict exactly-once processing.\" | **Correctness.** No matter how many times the user clicks or the network retries, the side effect happens exactly once. |\n",
        "\n",
        "## 4\\. Visual Diagram\n",
        "\n",
        "## 5\\. When to Use It (and When NOT to)\n",
        "\n",
        "  * \u2705 **Use when:**\n",
        "      * **Payments:** Essential for any financial transaction.\n",
        "      * **Creation:** `POST` requests that create resources (e.g., \"Create Order\").\n",
        "      * **Webhooks:** Receiving events from Stripe/Twilio (they will retry if you don't respond 200 OK, so you must handle duplicates).\n",
        "  * \u274c **Avoid when:**\n",
        "      * **GET Requests:** Reading data is naturally idempotent. (Reading a blog post twice doesn't change the blog post).\n",
        "      * **PUT Requests:** Often naturally idempotent (Updating \"Name=John\" to \"Name=John\" twice is usually fine), but be careful with relative updates (\"Add +1 to Score\").\n",
        "\n",
        "## 6\\. Implementation Example (Pseudo-code)\n",
        "\n",
        "**Scenario:** A Payment API using Redis for deduplication.\n",
        "\n",
        "```python\n",
        "import redis\n",
        "\n",
        "# Redis connection\n",
        "cache = redis.Redis(host='localhost', port=6379, db=0)\n",
        "\n",
        "def process_payment(request):\n",
        "    # 1. Extract the Idempotency Key\n",
        "    idem_key = request.headers.get('Idempotency-Key')\n",
        "    if not idem_key:\n",
        "        return HTTP_400(\"Missing Idempotency-Key header\")\n",
        "\n",
        "    # 2. Check if we've seen this key (Atomic Check)\n",
        "    # redis_key structure: \"idem:req_123\"\n",
        "    redis_key = f\"idem:{idem_key}\"\n",
        "    \n",
        "    # Try to lock this key. \n",
        "    # If setnx returns 0, it means the key already exists (Duplicate Request).\n",
        "    # We set a 24-hour expiration so keys don't fill up RAM forever.\n",
        "    is_new_request = cache.setnx(redis_key, \"PROCESSING\")\n",
        "    cache.expire(redis_key, 86400) # 24 hours\n",
        "\n",
        "    if not is_new_request:\n",
        "        # 3. Handle Duplicate\n",
        "        # Wait for the first request to finish if it's still processing\n",
        "        stored_response = wait_for_result(redis_key)\n",
        "        return stored_response\n",
        "\n",
        "    # 4. Process the Actual Logic (The dangerous part)\n",
        "    try:\n",
        "        result = payment_gateway.charge(request.amount)\n",
        "        response_data = {\"status\": \"success\", \"tx_id\": result.id}\n",
        "        \n",
        "        # 5. Update the cache with the real result\n",
        "        cache.set(redis_key, json.dumps(response_data))\n",
        "        \n",
        "        return HTTP_200(response_data)\n",
        "        \n",
        "    except Exception as e:\n",
        "        # If it failed, delete the key so they can retry? \n",
        "        # Or store the error? Depends on business logic.\n",
        "        cache.delete(redis_key)\n",
        "        return HTTP_500(\"Payment Failed\")\n",
        "```\n",
        "\n",
        "## 7\\. The \"Scope\" of Idempotency Keys\n",
        "\n",
        "A common mistake is reusing keys inappropriately.\n",
        "\n",
        "  * **Scope by User:** The key `order_1` for User A is different from `order_1` for User B? Usually, yes.\n",
        "  * **Expiration:** How long do you keep the keys?\n",
        "      * **Too short (5s):** If a retry comes 6 seconds later, it duplicates.\n",
        "      * **Too long (Forever):** You run out of storage.\n",
        "      * **Senior Rule:** Keep keys for slightly longer than your maximum retry window (e.g., 24 to 48 hours).\n",
        "\n",
        "## 8\\. HTTP Verbs & Idempotency\n",
        "\n",
        "  * `GET`: Idempotent (Safe).\n",
        "  * `PUT`: Idempotent (Usually replaces state).\n",
        "  * `DELETE`: Idempotent (Deleting a deleted record returns 404, but state remains \"deleted\").\n",
        "  * `POST`: **NOT Idempotent.** This is where you strictly need the pattern."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### \ud83d\udcc4 `03-data-management-consistency/16-transactional-outbox.md`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 16\\. Transactional Outbox Pattern\n",
        "\n",
        "## 1\\. The Concept\n",
        "\n",
        "The Transactional Outbox pattern ensures **consistency** between the application's database and a message broker (like Kafka or RabbitMQ). It solves the \"Dual Write Problem\" by saving the message to a database table (the \"Outbox\") *in the same transaction* as the business data change. A separate background process then reads the Outbox and safely publishes the messages to the broker.\n",
        "\n",
        "## 2\\. The Problem\n",
        "\n",
        "  * **Scenario:** A user signs up. You need to:\n",
        "    1.  Insert the user into the `Users` table (Postgres).\n",
        "    2.  Publish a `UserCreated` event to Kafka so the Email Service can send a welcome email.\n",
        "  * **The Dual Write Problem:** You cannot transactionally write to Postgres and Kafka simultaneously.\n",
        "      * **Scenario A:** You save to DB, then crash before publishing to Kafka.\n",
        "          * *Result:* User exists, but no email is sent. System is inconsistent.\n",
        "      * **Scenario B:** You publish to Kafka, then the DB insert fails (rollback).\n",
        "          * *Result:* Email is sent for a user that doesn't exist. System is inconsistent.\n",
        "\n",
        "## 3\\. The Solution\n",
        "\n",
        "Use the database transaction to guarantee atomicity.\n",
        "\n",
        "1.  **The Atomic Write:** In a single SQL transaction, insert the user into the `Users` table **AND** insert the event payload into a standard SQL table called `Outbox`. If the DB transaction rolls back, both vanish. If it commits, both exist.\n",
        "2.  **The Relay:** A separate process (The \"Message Relay\" or \"Poller\") repeatedly checks the `Outbox` table.\n",
        "3.  **The Publish:** The Relay picks up the pending messages and pushes them to Kafka.\n",
        "4.  **The Cleanup:** Once Kafka confirms receipt (ACK), the Relay marks the Outbox record as \"Sent\" or deletes it.\n",
        "\n",
        "### Junior vs. Senior View\n",
        "\n",
        "| Perspective | Approach | Outcome |\n",
        "| :--- | :--- | :--- |\n",
        "| **Junior** | \"Just put the `producer.send()` call right after the `db.save()` call. It works on my machine.\" | **Data Loss.** In production, networks blink. The app crashes. You end up with \"ghost\" users who never triggered downstream workflows. |\n",
        "| **Senior** | \"I trust the database transaction. I write the event to the `Outbox` table inside the SQL transaction. I let a Debezium connector or a Poller handle the actual network call to Kafka.\" | **Guaranteed Delivery.** (At-Least-Once). Even if the power goes out the millisecond after the commit, the event is safely on disk and will be sent when the system recovers. |\n",
        "\n",
        "## 4\\. Visual Diagram\n",
        "\n",
        "## 5\\. When to Use It (and When NOT to)\n",
        "\n",
        "  * \u2705 **Use when:**\n",
        "      * **Critical Events:** Financial transactions, user signups, inventory changes where downstream consistency is mandatory.\n",
        "      * **Distributed Systems:** Any time a microservice needs to notify another microservice about a state change.\n",
        "      * **Legacy Systems:** You can add an Outbox table to a legacy monolith to start emitting events without changing the core code much.\n",
        "  * \u274c **Avoid when:**\n",
        "      * **Fire-and-Forget:** Logging, metrics, or non-critical notifications where losing 0.1% of messages is acceptable.\n",
        "      * **High Throughput / Low Latency:** Writing every single message to a SQL table adds I/O overhead. If you need millions of events per second, streaming logs directly might be better.\n",
        "\n",
        "## 6\\. Implementation Example (Pseudo-code)\n",
        "\n",
        "**Scenario:** User Signup.\n",
        "\n",
        "### Step 1: The Application (Atomic Commit)\n",
        "\n",
        "```python\n",
        "def register_user(username, email):\n",
        "    # Start SQL Transaction\n",
        "    with db.transaction():\n",
        "        # 1. Write Business Data\n",
        "        user = db.execute(\n",
        "            \"INSERT INTO users (username, email) VALUES (?, ?)\", \n",
        "            (username, email)\n",
        "        )\n",
        "        \n",
        "        # 2. Write Event to Outbox (Same Transaction!)\n",
        "        event_payload = json.dumps({\"type\": \"UserCreated\", \"id\": user.id})\n",
        "        db.execute(\n",
        "            \"INSERT INTO outbox (topic, payload, status) VALUES (?, ?, 'PENDING')\",\n",
        "            (\"user_events\", event_payload)\n",
        "        )\n",
        "    \n",
        "    # Commit happens here automatically.\n",
        "    # Either BOTH exist, or NEITHER exists.\n",
        "```\n",
        "\n",
        "### Step 2: The Message Relay (The Poller)\n",
        "\n",
        "*Runs in a background loop or separate process.*\n",
        "\n",
        "```python\n",
        "def process_outbox():\n",
        "    while True:\n",
        "        # 1. Fetch pending messages\n",
        "        messages = db.query(\"SELECT * FROM outbox WHERE status='PENDING' LIMIT 10\")\n",
        "        \n",
        "        for msg in messages:\n",
        "            try:\n",
        "                # 2. Publish to Broker (e.g., Kafka/RabbitMQ)\n",
        "                kafka_producer.send(topic=msg.topic, value=msg.payload)\n",
        "                \n",
        "                # 3. Mark as Sent (or Delete)\n",
        "                db.execute(\"UPDATE outbox SET status='SENT' WHERE id=?\", (msg.id,))\n",
        "                \n",
        "            except KafkaError:\n",
        "                # Log and retry later (don't mark as sent)\n",
        "                logger.error(f\"Failed to send msg {msg.id}\")\n",
        "\n",
        "        time.sleep(1)\n",
        "```\n",
        "\n",
        "## 7\\. Advanced: Log Tailing (CDC)\n",
        "\n",
        "The \"Polling\" approach (Querying SQL every 1 second) can hurt database performance.\n",
        "**The Senior approach** is often **Change Data Capture (CDC)**.\n",
        "\n",
        "  * Instead of a Poller code, use a tool like **Debezium**.\n",
        "  * Debezium reads the database's *Transaction Log* (Postgres WAL or MySQL Binlog) directly.\n",
        "  * It sees the insert into the `Outbox` table and streams it to Kafka automatically.\n",
        "  * This has lower latency and zero performance impact on the query engine.\n",
        "\n",
        "## 8\\. Idempotency on the Consumer\n",
        "\n",
        "The Outbox pattern guarantees **At-Least-Once** delivery.\n",
        "\n",
        "  * If the Relay sends the message to Kafka, but crashes *before* updating the DB to \"SENT,\" it will send the message again when it restarts.\n",
        "  * **Crucial:** The Consumer (the Email Service) must be **Idempotent** (Pattern \\#15) to handle receiving the same \"UserCreated\" event twice without sending two emails.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### \ud83d\udcc4 `03-data-management-consistency/README.md`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83d\udcbe Group 3: Data Management & Consistency\n",
        "\n",
        "## Overview\n",
        "\n",
        "**\"Data outlives code. If you corrupt the state, no amount of bug fixing will save you.\"**\n",
        "\n",
        "In a monolithic application, you have one database and ACID transactions. Life is simple. In a distributed system, you have many databases, network partitions, and no global clock. Life is hard.\n",
        "\n",
        "This module addresses the hardest problems in software architecture:\n",
        "\n",
        "1.  **Distributed Transactions:** How to update two databases at once without a global lock.\n",
        "2.  **State Synchronization:** How to keep the search index in sync with the primary database.\n",
        "3.  **Reliability:** How to ensure a message is processed exactly once (or at least once) despite network failures.\n",
        "\n",
        "The patterns here move you away from \"Strong Consistency\" (everything is instantly correct everywhere) to \"Eventual Consistency\" (everything will be correct... eventually).\n",
        "\n",
        "## \ud83d\udcdc Pattern Index\n",
        "\n",
        "| Pattern | Goal | Senior \"Soundbite\" |\n",
        "| :--- | :--- | :--- |\n",
        "| **[12. CQRS](https://www.google.com/search?q=./12-cqrs.md)** | **Read/Write Separation** | \"Don't use the same model for complex validation and high-speed searching.\" |\n",
        "| **[13. Event Sourcing](https://www.google.com/search?q=./13-event-sourcing.md)** | **Audit & History** | \"Don't just store the current balance. Store every deposit and withdrawal that got us there.\" |\n",
        "| **[14. Saga Pattern](https://www.google.com/search?q=./14-saga-pattern.md)** | **Distributed Transactions** | \"We can't use 2-Phase Commit. If the Hotel fails, trigger a Compensating Transaction to refund the Flight.\" |\n",
        "| **[15. Idempotency](https://www.google.com/search?q=./15-idempotency.md)** | **Duplicate Handling** | \"If the user clicks 'Pay' twice, we must only charge them once. Check the Request ID.\" |\n",
        "| **[16. Transactional Outbox](https://www.google.com/search?q=./16-transactional-outbox.md)** | **Message Reliability** | \"Never fire-and-forget to Kafka. Write the event to the DB first, then relay it.\" |\n",
        "\n",
        "## \ud83e\udde0 The Data Checklist\n",
        "\n",
        "Before deploying a distributed data system, a Senior Architect asks:\n",
        "\n",
        "1.  **The \"Split-Brain\" Test:** If the network between the US and EU regions fails, do we stop writing (Consistency) or allow divergent writes (Availability)?\n",
        "2.  **The \"Replay\" Test:** If a bug corrupted the data last Tuesday, can we replay the event log to fix the state, or is the data lost forever? (Event Sourcing).\n",
        "3.  **The \"Partial Failure\" Test:** If the Order Service succeeds but the Email Service fails, is the system in a broken state? (Saga).\n",
        "4.  **The \"Double-Click\" Test:** What happens if I send the exact same API request 10 times in 10 milliseconds? (Idempotency).\n",
        "\n",
        "## \u26a0\ufe0f Common Pitfalls in This Module\n",
        "\n",
        "  * **Premature CQRS:** Implementing full Command/Query separation for a simple CRUD app. It doubles your code volume for zero gain.\n",
        "  * **The \"Magic\" Event Bus:** Assuming that if you publish a message to RabbitMQ, it *will* arrive. It won't. You need Outboxes and Acknowledgments.\n",
        "  * **Ignoring Order:** Distributed events often arrive out of order. If \"User Updated\" arrives before \"User Created,\" your system must handle it (or reject it).\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}